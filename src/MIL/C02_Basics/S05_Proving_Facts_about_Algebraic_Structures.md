## Proving Facts about Algebraic Structures

In :numref:`proving_identities_in_algebraic_structures`,
we saw that many common identities governing the real numbers hold
in more general classes of algebraic structures,
such as commutative rings.
We can use any axioms we want to describe an algebraic structure,
not just equations.
For example, a _partial order_ consists of a set with a
binary relation that is reflexive, transitive, and antisymmetric.
like `≤` on the real numbers.
Lean knows about partial orders:
TEXT. -/
section

```lean
variable {α : Type*} [PartialOrder α]
variable (x y z : α)

#check x ≤ y
#check (le_refl x : x ≤ x)
#check (le_trans : x ≤ y → y ≤ z → x ≤ z)
#check (le_antisymm : x ≤ y → y ≤ x → x = y)

```

Here we are adopting the Mathlib convention of using
letters like `α`, `β`, and `γ`
(entered as `\a`, `\b`, and `\g`)
for arbitrary types.
The library often uses letters like `R` and `G`
for the carriers of algebraic structures like rings and groups,
respectively,
but in general Greek letters are used for types,
especially when there is little or no structure
associated with them.

Associated to any partial order, `≤`,
there is also a _strict partial order_, `<`,
which acts somewhat like `<` on the real numbers.
Saying that `x` is less than `y` in this order
is equivalent to saying that it is less-than-or-equal to `y`
and not equal to `y`.

```lean
#check x < y
#check (lt_irrefl x : ¬ (x < x))
#check (lt_trans : x < y → y < z → x < z)
#check (lt_of_le_of_lt : x ≤ y → y < z → x < z)
#check (lt_of_lt_of_le : x < y → y ≤ z → x < z)

example : x < y ↔ x ≤ y ∧ x ≠ y :=
  lt_iff_le_and_ne
```

In this example, the symbol `∧` stands for "and,"
the symbol `¬` stands for "not," and
`x ≠ y` abbreviates `¬ (x = y)`.
In :numref:`Chapter %s <logic>`, you will learn how to use
these logical connectives to _prove_ that `<`
has the properties indicated.

A _lattice_ is a structure that extends a partial
order with operations `⊓` and `⊔` that are
analogous to `min` and `max` on the real numbers:

```lean
variable {α : Type*} [Lattice α]
variable (x y z : α)

#check x ⊓ y
#check (inf_le_left : x ⊓ y ≤ x)
#check (inf_le_right : x ⊓ y ≤ y)
#check (le_inf : z ≤ x → z ≤ y → z ≤ x ⊓ y)
#check x ⊔ y
#check (le_sup_left : x ≤ x ⊔ y)
#check (le_sup_right : y ≤ x ⊔ y)
#check (sup_le : x ≤ z → y ≤ z → x ⊔ y ≤ z)
```

The characterizations of `⊓` and `⊔` justify calling them
the _greatest lower bound_ and _least upper bound_, respectively.
You can type them in VS code using `\glb` and `\lub`.
The symbols are also often called then _infimum_ and
the _supremum_,
and Mathlib refers to them as `inf` and `sup` in
theorem names.
To further complicate matters,
they are also often called _meet_ and _join_.
Therefore, if you work with lattices,
you have to keep the following dictionary in mind:

- `⊓` is the _greatest lower bound_, _infimum_, or _meet_.

- `⊔` is the _least upper bound_, _supremum_, or _join_.

Some instances of lattices include:

- `min` and `max` on any total order, such as the integers or real numbers with `≤`

- `∩` and `∪` on the collection of subsets of some domain, with the ordering `⊆`

- `∧` and `∨` on boolean truth values, with ordering `x ≤ y` if either `x` is false or `y` is true

- `gcd` and `lcm` on the natural numbers (or positive natural numbers), with the divisibility ordering, `∣`

- the collection of linear subspaces of a vector space,
  where the greatest lower bound is given by the intersection,
  the least upper bound is given by the sum of the two spaces,
  and the ordering is inclusion

- the collection of topologies on a set (or, in Lean, a type),
  where the greatest lower bound of two topologies consists of
  the topology that is generated by their union,
  the least upper bound is their intersection,
  and the ordering is reverse inclusion

You can check that, as with `min` / `max` and `gcd` / `lcm`,
you can prove the commutativity and associativity of the infimum and supremum
using only their characterizing axioms,
together with `le_refl` and `le_trans`.

Using `apply le_trans` when seeing a goal `x ≤ z` is not a great idea.
Indeed Lean has no way to guess which intermediate element `y` we
want to use.
So `apply le_trans` produces three goals that look like`x ≤ ?a`, `?a ≤ z`
and `α` where `?a` (probably with a more complicated auto-generated name) stands
for the mysterious `y`.
The last goal, with type `α`, is to provide the value of `y`.
It comes lasts because Lean hopes to automatically infer it from the proof of
the first goal `x ≤ ?a`.
In order to avoid this unappealing situation, you can use the `calc` tactic
to explicitly provide `y`.
Alternatively, you can use the `trans` tactic
which takes `y` as an argument and produces the expected goals `x ≤ y` and
`y ≤ z`.
Of course you can also avoid this issue by providing directly a full proof such as
`exact le_trans inf_le_left inf_le_right`, but this requires a lot more
planning.

```lean
example : x ⊓ y = y ⊓ x := by
  sorry

example : x ⊓ y ⊓ z = x ⊓ (y ⊓ z) := by
  sorry

example : x ⊔ y = y ⊔ x := by
  sorry

example : x ⊔ y ⊔ z = x ⊔ (y ⊔ z) := by
  sorry
```

You can find these theorems in the Mathlib as `inf_comm`, `inf_assoc`,
`sup_comm`, and `sup_assoc`, respectively.

Another good exercise is to prove the _absorption laws_
using only those axioms:

```lean
theorem absorb1 : x ⊓ (x ⊔ y) = x := by
  sorry

theorem absorb2 : x ⊔ x ⊓ y = x := by
  sorry
```

These can be found in Mathlib with the names `inf_sup_self` and `sup_inf_self`.

A lattice that satisfies the additional identities
`x ⊓ (y ⊔ z) = (x ⊓ y) ⊔ (x ⊓ z)` and
`x ⊔ (y ⊓ z) = (x ⊔ y) ⊓ (x ⊔ z)`
is called a _distributive lattice_. Lean knows about these too:

```lean
variable {α : Type*} [DistribLattice α]
variable (x y z : α)

#check (inf_sup_left x y z : x ⊓ (y ⊔ z) = x ⊓ y ⊔ x ⊓ z)
#check (inf_sup_right x y z : (x ⊔ y) ⊓ z = x ⊓ z ⊔ y ⊓ z)
#check (sup_inf_left x y z : x ⊔ y ⊓ z = (x ⊔ y) ⊓ (x ⊔ z))
#check (sup_inf_right x y z : x ⊓ y ⊔ z = (x ⊔ z) ⊓ (y ⊔ z))
```

The left and right versions are easily shown to be
equivalent, given the commutativity of `⊓` and `⊔`.
It is a good exercise to show that not every lattice
is distributive
by providing an explicit description of a
nondistributive lattice with finitely many elements.
It is also a good exercise to show that in any lattice,
either distributivity law implies the other:

```lean
variable {α : Type*} [Lattice α]
variable (a b c : α)

example (h : ∀ x y z : α, x ⊓ (y ⊔ z) = x ⊓ y ⊔ x ⊓ z) : a ⊔ b ⊓ c = (a ⊔ b) ⊓ (a ⊔ c) := by
  sorry

example (h : ∀ x y z : α, x ⊔ y ⊓ z = (x ⊔ y) ⊓ (x ⊔ z)) : a ⊓ (b ⊔ c) = a ⊓ b ⊔ a ⊓ c := by
  sorry
```

It is possible to combine axiomatic structures into larger ones.
For example, a _strict ordered ring_ consists of a commutative ring together
with a partial order on the carrier
satisfying additional axioms that say that the ring operations
are compatible with the order:

```lean
variable {R : Type*} [StrictOrderedRing R]
variable (a b c : R)

#check (add_le_add_left : a ≤ b → ∀ c, c + a ≤ c + b)
#check (mul_pos : 0 < a → 0 < b → 0 < a * b)
```

:numref:`Chapter %s <logic>` will provide the means to derive the following from `mul_pos`
and the definition of `<`:

```lean
#check (mul_nonneg : 0 ≤ a → 0 ≤ b → 0 ≤ a * b)
```

It is then an extended exercise to show that many common facts
used to reason about arithmetic and the ordering on the real
numbers hold generically for any ordered ring.
Here are a couple of examples you can try,
using only properties of rings, partial orders, and the facts
enumerated in the last two examples:

```lean
example (h : a ≤ b) : 0 ≤ b - a := by
  sorry

example (h: 0 ≤ b - a) : a ≤ b := by
  sorry

example (h : a ≤ b) (h' : 0 ≤ c) : a * c ≤ b * c := by
  sorry
```

Finally, here is one last example.
A _metric space_ consists of a set equipped with a notion of
distance, `dist x y`,
mapping any pair of elements to a real number.
The distance function is assumed to satisfy the following axioms:

```lean
variable {X : Type*} [MetricSpace X]
variable (x y z : X)

#check (dist_self x : dist x x = 0)
#check (dist_comm x y : dist x y = dist y x)
#check (dist_triangle x y z : dist x z ≤ dist x y + dist y z)
```

Having mastered this section,
you can show that it follows from these axioms that distances are
always nonnegative:

```lean
example (x y : X) : 0 ≤ dist x y := by
  sorry
```

We recommend making use of the theorem `nonneg_of_mul_nonneg_left`.
As you may have guessed, this theorem is called `dist_nonneg` in Mathlib.
